# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AtD_NeqPvAlNm8kzUnezhnlo4H2UCDuG
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib

def preprocess_data(input_file, output_dir):
    """
    Preprocess the Boston Housing data

    Args:
        input_file (str): Path to raw data CSV
        output_dir (str): Directory to save processed data
    """
    # Load data
    df = pd.read_csv(input_file)

    # Handle outliers
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    for col in numeric_cols:
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        df[col] = df[col].clip(lower_bound, upper_bound)

    # Split data
    X = df.drop('medv', axis=1)
    y = df['medv']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Save processed data
    pd.DataFrame(X_train_scaled, columns=X.columns).to_csv(f"{output_dir}/X_train.csv", index=False)
    pd.DataFrame(X_test_scaled, columns=X.columns).to_csv(f"{output_dir}/X_test.csv", index=False)
    y_train.to_csv(f"{output_dir}/y_train.csv", index=False)
    y_test.to_csv(f"{output_dir}/y_test.csv", index=False)
    joblib.dump(scaler, f"{output_dir}/scaler.pkl")

    print("Data preprocessing completed successfully!")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', type=str, default='data/BostonHousing.csv',
                       help='Path to input CSV file')
    parser.add_argument('--output', type=str, default='data/processed',
                       help='Directory to save processed data')
    args = parser.parse_args()

    preprocess_data(args.input, args.output)
